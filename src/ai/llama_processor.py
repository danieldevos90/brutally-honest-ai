"""
LLAMA AI Processing Module for Brutally Honest AI
Handles audio transcription and analysis using local LLAMA models
"""

import asyncio
import logging
import json
import tempfile
import os
from typing import Dict, Any, Optional
from dataclasses import dataclass
from pathlib import Path

logger = logging.getLogger(__name__)

@dataclass
class AIProcessingResult:
    """Result from AI processing with fact-checking"""
    success: bool
    transcription: Optional[str] = None
    analysis: Optional[str] = None
    summary: Optional[str] = None
    sentiment: Optional[str] = None
    keywords: Optional[list] = None
    fact_check: Optional[str] = None
    brutal_honesty: Optional[str] = None
    credibility_score: Optional[float] = None
    questionable_claims: Optional[list] = None
    corrections: Optional[list] = None
    confidence: Optional[float] = None
    processing_time: Optional[float] = None
    error: Optional[str] = None

class LLAMAProcessor:
    """LLAMA AI processor for audio analysis"""
    
    def __init__(self, model_path: str = None, whisper_model: str = "medium"):
        self.model_path = model_path or "llama-2-7b-chat.gguf"  # Default model
        self.whisper_model = whisper_model  # Use 'medium' model for better accuracy
        self.is_initialized = False
        
        # Check if models are available
        self.whisper_available = self._check_whisper()
        self.llama_available = self._check_llama()
        
    def _check_whisper(self) -> bool:
        """Check if Whisper is available for transcription"""
        try:
            import whisper
            return True
        except ImportError:
            logger.warning("Whisper not available - install with: pip install openai-whisper")
            return False
    
    def _check_llama(self) -> bool:
        """Check if LLAMA is available"""
        try:
            # Check for llama-cpp-python
            import llama_cpp
            return True
        except ImportError:
            try:
                # Check for ollama
                import requests
                response = requests.get("http://localhost:11434/api/tags", timeout=2)
                return response.status_code == 200
            except:
                logger.warning("LLAMA not available - install llama-cpp-python or run Ollama")
                return False
    
    def _preprocess_audio(self, audio_path: str) -> str:
        """Preprocess audio for better transcription accuracy"""
        try:
            import librosa
            import soundfile as sf
            import numpy as np
            from scipy import signal
            
            logger.info("üîß Starting advanced audio preprocessing...")
            
            # Load audio with librosa for preprocessing
            logger.info(f"üìÇ Loading audio file: {audio_path}")
            audio, sr = librosa.load(audio_path, sr=16000)  # Resample to 16kHz
            original_duration = len(audio) / sr
            logger.info(f"üéµ Original audio: {original_duration:.2f}s at {sr}Hz, {len(audio)} samples")
            
            # Check if audio is empty or too short
            if len(audio) == 0:
                logger.warning("‚ö†Ô∏è Audio file is empty - skipping preprocessing")
                return audio_path
            
            if original_duration < 0.1:  # Less than 100ms
                logger.warning(f"‚ö†Ô∏è Audio too short ({original_duration:.3f}s) - skipping preprocessing")
                return audio_path
            
            # 1. Noise reduction using spectral gating
            logger.info("üîá Applying noise reduction...")
            # Estimate noise from first 0.5 seconds (assuming it's quiet)
            noise_sample_length = min(int(0.5 * sr), len(audio) // 4)
            noise_sample = audio[:noise_sample_length]
            noise_power = np.mean(noise_sample ** 2)
            
            # Apply gentle noise gate
            noise_threshold = noise_power * 3  # Adjust threshold
            audio = np.where(audio ** 2 > noise_threshold, audio, audio * 0.1)
            
            # 2. High-pass filter to remove low-frequency noise
            logger.info("üéõÔ∏è Applying high-pass filter...")
            nyquist = sr // 2
            high_cutoff = 80  # Remove frequencies below 80Hz
            b, a = signal.butter(4, high_cutoff / nyquist, btype='high')
            audio = signal.filtfilt(b, a, audio)
            
            # 3. Dynamic range compression for consistent volume
            logger.info("üìä Applying dynamic range compression...")
            # Soft compression to even out volume levels
            threshold = 0.3
            ratio = 4.0
            audio_abs = np.abs(audio)
            mask = audio_abs > threshold
            compressed = np.copy(audio)
            compressed[mask] = np.sign(audio[mask]) * (threshold + (audio_abs[mask] - threshold) / ratio)
            audio = compressed
            
            # 4. Normalize amplitude
            logger.info("üîä Normalizing audio amplitude...")
            audio = librosa.util.normalize(audio)
            
            # 5. Advanced silence trimming with better parameters
            logger.info("‚úÇÔ∏è Trimming silence (top_db=20, frame_length=1024)...")
            audio_trimmed, _ = librosa.effects.trim(
                audio, 
                top_db=20,  # Less aggressive to preserve speech
                frame_length=1024,  # Smaller frame for better speech detection
                hop_length=256
            )
            trimmed_duration = len(audio_trimmed) / sr
            logger.info(f"‚è±Ô∏è Audio after trimming: {trimmed_duration:.2f}s ({len(audio_trimmed)} samples)")
            
            # 5.5. Ensure minimum audio length for Whisper
            min_duration = 0.5  # Minimum 0.5 seconds
            if trimmed_duration < min_duration:
                logger.info(f"‚ö†Ô∏è Audio too short ({trimmed_duration:.2f}s), padding to {min_duration}s")
                padding_samples = int((min_duration - trimmed_duration) * sr)
                audio_trimmed = np.pad(audio_trimmed, (0, padding_samples), mode='constant', constant_values=0)
                trimmed_duration = len(audio_trimmed) / sr
            
            # 6. Pre-emphasis filter (boosts high frequencies for better speech clarity)
            logger.info("üéØ Applying pre-emphasis filter...")
            pre_emphasis = 0.97
            audio_emphasized = np.append(audio_trimmed[0], audio_trimmed[1:] - pre_emphasis * audio_trimmed[:-1])
            
            # 7. Final normalization
            audio_final = librosa.util.normalize(audio_emphasized)
            
            # Save preprocessed audio
            processed_path = audio_path.replace('.wav', '_processed.wav')
            sf.write(processed_path, audio_final, sr)
            logger.info(f"üíæ Enhanced audio saved: {processed_path}")
            logger.info("‚úÖ Advanced audio preprocessing completed successfully")
            
            return processed_path
            
        except ImportError:
            logger.warning("‚ö†Ô∏è librosa not available - using original audio without preprocessing")
            return audio_path
        except Exception as e:
            logger.warning(f"‚ùå Audio preprocessing failed: {e} - using original audio")
            return audio_path
    
    async def initialize(self) -> bool:
        """Initialize the AI models"""
        try:
            if self.whisper_available:
                import whisper
                logger.info(f"üé§ Loading Whisper model: {self.whisper_model}")
                self.whisper = whisper.load_model(self.whisper_model)
                logger.info("‚úÖ Whisper model loaded successfully")
            
            if self.llama_available:
                try:
                    # Try llama-cpp-python first
                    from llama_cpp import Llama
                    logger.info(f"ü¶ô Loading LLAMA model: {self.model_path}")
                    self.llama = Llama(
                        model_path=self.model_path,
                        n_ctx=2048,  # Context window
                        n_threads=4,  # CPU threads
                        verbose=False
                    )
                    self.llama_type = "cpp"
                    logger.info("‚úÖ LLAMA model loaded successfully")
                except Exception as e:
                    # Fall back to Ollama
                    logger.info("üì° Using Ollama for LLAMA processing")
                    self.llama_type = "ollama"
                    self.llama = None
            
            self.is_initialized = True
            return True
            
        except Exception as e:
            logger.error(f"Failed to initialize AI models: {e}")
            return False
    
    
    async def transcribe_audio(self, audio_data: bytes, filename: str = "audio.wav") -> str:
        """Transcribe audio using Whisper with preprocessing"""
        if not self.whisper_available:
            return "Transcription not available - Whisper not installed"
        
        try:
            # Save audio to temporary file
            logger.info(f"üíæ Creating temporary file for audio processing...")
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                temp_file.write(audio_data)
                temp_path = temp_file.name
            logger.info(f"üìÅ Temporary file created: {temp_path} ({len(audio_data)} bytes)")
            
            # Preprocess audio for better transcription
            logger.info("üîÑ Starting audio preprocessing pipeline...")
            processed_path = self._preprocess_audio(temp_path)
            
            # Transcribe using Whisper with improved settings
            logger.info(f"üé§ Starting Whisper transcription for: {filename}")
            logger.info(f"üîß Whisper model: {self.whisper_model}")
            logger.info("‚öôÔ∏è Optimized transcription strategy:")
            logger.info("   ‚Ä¢ Primary method: Raw audio (unprocessed - most accurate)")
            logger.info("   ‚Ä¢ Language: Auto-detect (Dutch/English supported)")
            logger.info("   ‚Ä¢ Content: Universal (no pre-coded assumptions)")
            logger.info("   ‚Ä¢ Temperature: 0.1 (deterministic)")
            logger.info("   ‚Ä¢ No speech threshold: 0.5 (balanced)")
            logger.info("   ‚Ä¢ Log prob threshold: -1.0 (quality focused)")
            logger.info("   ‚Ä¢ Compression ratio threshold: 2.0 (natural speech)")
            logger.info("   ‚Ä¢ Word timestamps: enabled")
            logger.info("   ‚Ä¢ Fallback: Processed audio if raw fails")
            logger.info("   ‚Ä¢ FP16: disabled (using FP32)")
            
            # Use raw audio transcription as primary method (most accurate)
            logger.info("üéØ Primary: Raw audio transcription (most accurate)...")
            try:
                result = self.whisper.transcribe(
                    temp_path,  # Use original, unprocessed audio
                    language=None,
                    task="transcribe",
                    temperature=0.1,
                    no_speech_threshold=0.5,
                    logprob_threshold=-1.0,
                    compression_ratio_threshold=2.0,
                    condition_on_previous_text=False,
                    word_timestamps=True,
                    fp16=False
                )
                logger.info(f"‚úÖ Raw audio result: '{result['text'].strip()}'")
                
                # Check if result is reasonable
                text = result['text'].strip()
                if len(text) > 0 and not text.lower() in ['you can fly', 'the fox can fly']:
                    logger.info("üèÜ Raw audio transcription successful - using this result")
                else:
                    logger.warning("‚ö†Ô∏è Raw audio gave poor result, trying fallback...")
                    raise Exception("Poor raw audio result")
                    
            except Exception as e:
                logger.warning(f"Raw audio transcription failed: {e}")
                logger.info("üîÑ Fallback: Trying processed audio...")
                
                # Fallback to processed audio if raw fails
                try:
                    result = self.whisper.transcribe(
                        processed_path,
                        language=None,
                        task="transcribe",
                        temperature=0.0,
                        no_speech_threshold=0.3,
                        logprob_threshold=-0.8,
                        compression_ratio_threshold=2.4,
                        condition_on_previous_text=False,
                        word_timestamps=True,
                        fp16=False,
                        beam_size=5,
                        best_of=5,
                        patience=1.0
                    )
                    logger.info(f"‚úÖ Processed audio fallback: '{result['text'].strip()}'")
                except Exception as e2:
                    logger.error(f"Both raw and processed audio failed: {e2}")
                    raise Exception("All transcription methods failed")
            
            # Clean up temp files
            logger.info("üßπ Cleaning up temporary files...")
            os.unlink(temp_path)
            if processed_path != temp_path:
                os.unlink(processed_path)
                logger.info("üóëÔ∏è Preprocessed file cleaned up")
            
            transcription = result["text"].strip()
            detected_language = result.get("language", "unknown")
            
            # Check for repetitive patterns and clean them
            cleaned_transcription = self._clean_repetitive_text(transcription)
            if cleaned_transcription != transcription:
                logger.info(f"üßπ Cleaned repetitive text: '{transcription}' ‚Üí '{cleaned_transcription}'")
                transcription = cleaned_transcription
            
            logger.info(f"‚úÖ Transcription completed successfully!")
            logger.info(f"üåç Detected language: {detected_language}")
            logger.info(f"üìù Result: '{transcription}' ({len(transcription)} characters)")
            
            # Log detailed confidence information if available
            if "segments" in result and result["segments"]:
                avg_confidence = sum(seg.get("avg_logprob", 0) for seg in result["segments"]) / len(result["segments"])
                logger.info(f"üìä Average confidence: {avg_confidence:.3f}")
                logger.info(f"üî¢ Number of segments: {len(result['segments'])}")
                
                # Log individual segment details for debugging
                for i, segment in enumerate(result["segments"][:3]):  # Show first 3 segments
                    start_time = segment.get("start", 0)
                    end_time = segment.get("end", 0)
                    text = segment.get("text", "").strip()
                    confidence = segment.get("avg_logprob", 0)
                    logger.info(f"   Segment {i+1}: [{start_time:.1f}s-{end_time:.1f}s] '{text}' (conf: {confidence:.3f})")
                
                if len(result["segments"]) > 3:
                    logger.info(f"   ... and {len(result['segments']) - 3} more segments")
            else:
                logger.warning("‚ö†Ô∏è No segment information available in transcription result")
            
            return transcription
            
        except Exception as e:
            logger.error(f"Transcription failed: {e}")
            return f"Transcription failed: {str(e)}"
    
    async def analyze_with_llama(self, transcription: str, filename: str, model: str = None, timeout: int = None) -> Dict[str, Any]:
        """Analyze transcription using LLAMA with fact-checking"""
        if not self.llama_available:
            return {
                "analysis": "LLAMA analysis not available - model not loaded",
                "sentiment": "neutral",
                "summary": "Analysis unavailable",
                "keywords": [],
                "fact_check": "Fact-checking unavailable",
                "brutal_honesty": "Analysis system not available",
                "credibility_score": 0.5,
                "questionable_claims": [],
                "corrections": []
            }
        
        try:
            # Create enhanced analysis prompt with fact-checking
            prompt = f"""
You are a brutally honest AI fact-checker and analyst. Analyze this audio transcription and provide comprehensive insights with fact-checking:

Transcription: "{transcription}"

Your task is to be BRUTALLY HONEST and fact-check every claim. Please provide:

1. **Content Analysis**: Brief analysis of the content and context
2. **Sentiment**: Overall emotional tone (positive, negative, neutral)
3. **Summary**: Concise 1-2 sentence summary
4. **Keywords**: Key topics mentioned
5. **Fact Check**: Rigorous fact-checking of all claims made
6. **Brutal Honesty**: Factual assessment - if wrong, explain why with facts
7. **Credibility Score**: Rate from 0.0 to 1.0 based on factual accuracy
8. **Questionable Claims**: List any dubious or unverified statements
9. **Corrections**: Provide corrections for any false or misleading information

Be thorough, critical, and don't hold back. If someone makes unsubstantiated claims, call them out AND provide the correct facts. If they're being misleading, expose it with evidence. If they're stating facts correctly, acknowledge it. Always include factual context in your brutal honesty assessment.

IMPORTANT: You MUST respond with ONLY a valid JSON object. Do not include any other text before or after the JSON. The response must start with {{ and end with }}.

JSON format:
{{
    "analysis": "detailed content analysis here",
    "sentiment": "positive/negative/neutral", 
    "summary": "brief summary here",
    "keywords": ["keyword1", "keyword2", "keyword3"],
    "fact_check": "comprehensive fact-checking analysis",
    "brutal_honesty": "brutally honest assessment with factual context - include actual facts to support your assessment",
    "credibility_score": 0.5,
    "questionable_claims": ["claim1", "claim2"],
    "corrections": ["correction1", "correction2"]
}}
"""
            
            logger.info(f"ü¶ô Starting LLAMA analysis for: {filename}")
            logger.info(f"üìÑ Transcription to analyze: '{transcription}' ({len(transcription)} chars)")
            logger.info(f"üîß LLAMA backend: {self.llama_type}")
            
            if self.llama_type == "cpp":
                # Use llama-cpp-python
                logger.info("üîÑ Sending prompt to llama-cpp-python...")
                logger.info("‚öôÔ∏è LLAMA settings: max_tokens=512, temperature=0.7")
                response = self.llama(
                    prompt,
                    max_tokens=512,
                    temperature=0.7,
                    stop=["</s>", "\n\n"]
                )
                result_text = response["choices"][0]["text"]
                logger.info(f"üì§ Raw LLAMA response length: {len(result_text)} characters")
            else:
                # Use Ollama API
                import requests
                logger.info("üîÑ Sending request to Ollama API (localhost:11434)...")
                # Use provided model or default
                model_name = model or "tinyllama:latest"
                request_timeout = timeout or 15
                
                logger.info(f"üîß Using model: {model_name}, timeout: {request_timeout}s")
                
                response = requests.post(
                    "http://localhost:11434/api/generate",
                    json={
                        "model": model_name,
                        "prompt": prompt,
                        "stream": False,
                        "keep_alive": "10m",  # Keep model loaded longer
                        "options": {
                            "num_predict": 100,  # Very short for fact-checking
                            "temperature": 0.3,  # Lower temp for more factual responses
                            "top_p": 0.9,
                            "repeat_penalty": 1.1
                        }
                    },
                    timeout=request_timeout
                )
                logger.info(f"üì° Ollama response status: {response.status_code}")
                response_data = response.json()
                result_text = response_data.get("response", "")
                logger.info(f"üì§ Raw LLAMA response length: {len(result_text)} characters")
            
            # Try to parse JSON response
            logger.info("üîç Parsing LLAMA response...")
            try:
                # First try direct parsing
                logger.info("üìã Attempting direct JSON parsing...")
                result = json.loads(result_text)
                logger.info("‚úÖ LLAMA analysis completed successfully - direct JSON parse")
                logger.info(f"üìä Analysis fields returned: {list(result.keys())}")
                return result
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è Direct JSON parsing failed: {e}")
                # Try to extract JSON from the response if it's embedded in other text
                import re
                logger.info("üîç Attempting to extract JSON from response text...")
                json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
                if json_match:
                    try:
                        logger.info("üìã Found JSON pattern, attempting to parse...")
                        result = json.loads(json_match.group())
                        logger.info("‚úÖ LLAMA analysis completed successfully - extracted JSON")
                        logger.info(f"üìä Analysis fields returned: {list(result.keys())}")
                        return result
                    except json.JSONDecodeError as e2:
                        logger.warning(f"‚ö†Ô∏è Extracted JSON parsing also failed: {e2}")
                
                # If JSON parsing fails, create structured response
                logger.warning("‚ùå JSON parsing failed completely, creating fallback structured response")
                logger.info(f"üìÑ Raw response preview: '{result_text[:100]}...'")
                return {
                    "analysis": result_text,
                    "sentiment": "neutral",
                    "summary": result_text[:100] + "..." if len(result_text) > 100 else result_text,
                    "keywords": [],
                    "fact_check": "Unable to parse fact-check results from LLAMA response",
                    "brutal_honesty": result_text[:200] + "..." if len(result_text) > 200 else result_text,
                    "credibility_score": 0.5,
                    "questionable_claims": [],
                    "corrections": []
                }
                
        except Exception as e:
            logger.error(f"‚ùå LLAMA analysis failed: {e}")
            return None
    
    def _create_fast_analysis(self, transcription: str) -> dict:
        """Create fast analysis without LLAMA for speed"""
        # Simple keyword extraction
        words = transcription.lower().split()
        keywords = [w.strip('.,!?') for w in words if len(w) > 3][:5]
        
        # Enhanced sentiment analysis for Dutch and English
        positive_words = [
            # English
            'good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic', 'love', 'like', 'happy', 'yes', 'correct', 'true', 'right', 'perfect', 'awesome', 'nice',
            # Dutch
            'goed', 'geweldig', 'fantastisch', 'mooi', 'leuk', 'fijn', 'blij', 'tevreden', 'super', 'top', 'prima', 'perfect', 'ja', 'juist', 'correct'
        ]
        negative_words = [
            # English  
            'bad', 'terrible', 'awful', 'hate', 'dislike', 'sad', 'angry', 'frustrated', 'no', 'wrong', 'false', 'incorrect', 'annoying', 'irritating', 'problem', 'issue', 'stupid',
            # Dutch
            'slecht', 'verschrikkelijk', 'haat', 'boos', 'gefrustreerd', 'irritant', 'vervelend', 'probleem', 'fout', 'verkeerd', 'dom', 'stom', 'nee', 'niet'
        ]
        
        pos_count = sum(1 for word in words if word in positive_words)
        neg_count = sum(1 for word in words if word in negative_words)
        
        # More specific sentiment detection
        if 'irritant' in transcription.lower() or 'irritating' in transcription.lower():
            sentiment = "frustrated"
        elif neg_count > pos_count:
            sentiment = "negative"
        elif pos_count > neg_count:
            sentiment = "positive"
        else:
            sentiment = "neutral"
        
        # Basic fact-checking patterns
        questionable_patterns = ['can fly', 'impossible', 'never', 'always', 'all', 'none', 'every']
        questionable_claims = [pattern for pattern in questionable_patterns if pattern in transcription.lower()]
        
        # Generate brutal honesty based on content
        if any(claim in transcription.lower() for claim in ['fox can fly', 'elephant can fly', 'impossible']):
            brutal_honesty = "This statement contains a clear factual error. Foxes cannot fly - they are terrestrial mammals without wings or the ability for powered flight. This appears to be either a test statement or a misunderstanding of basic animal biology."
            credibility = 0.1
        elif self._check_basic_math_errors(transcription):
            brutal_honesty = "This contains a basic mathematical error. The arithmetic is incorrect - please double-check your calculations."
            credibility = 0.1
        elif len(transcription.strip()) < 5:
            brutal_honesty = "This is too short to provide meaningful analysis. Please provide more substantial content for proper assessment."
            credibility = 0.5
        elif sentiment == "frustrated" and any(word in transcription.lower() for word in ['systeem', 'system', 'status', 'order', 'probleem', 'problem', 'fout', 'error', 'irritant']):
            brutal_honesty = "You're describing a technical issue with clear frustration. The 'irritant' at the end says it all - system bugs that make you think something is new when it's actually a refund can be maddening. Your problem-solving approach of checking the status logic was spot on."
            credibility = 0.9
        else:
            brutal_honesty = "The statement appears factually plausible based on basic analysis. However, detailed fact-checking would require more comprehensive verification."
            credibility = 0.7
        
        return {
            "analysis": f"Fast analysis of '{transcription}': {len(words)} words, {sentiment} sentiment detected.",
            "sentiment": sentiment,
            "summary": transcription[:100] + "..." if len(transcription) > 100 else transcription,
            "keywords": keywords,
            "fact_check": f"Basic pattern analysis completed. Found {len(questionable_claims)} potentially questionable elements.",
            "brutal_honesty": brutal_honesty,
            "credibility_score": credibility,
            "questionable_claims": questionable_claims,
            "corrections": ["Fast analysis mode - detailed corrections require full AI analysis"] if questionable_claims else []
        }
    
    def _check_basic_math_errors(self, text: str) -> bool:
        """Check for obvious mathematical errors"""
        import re
        
        # Look for basic arithmetic patterns like "X plus Y is Z" or "X + Y = Z"
        patterns = [
            r'(\d+)\s*(?:plus|\+)\s*(\d+)\s*(?:is|equals?|=)\s*(\d+)',
            r'(\d+)\s*(?:minus|-)\s*(\d+)\s*(?:is|equals?|=)\s*(\d+)',
            r'(\d+)\s*(?:times|\*|√ó)\s*(\d+)\s*(?:is|equals?|=)\s*(\d+)',
            r'(\d+)\s*(?:divided by|/|√∑)\s*(\d+)\s*(?:is|equals?|=)\s*(\d+)'
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, text.lower())
            for match in matches:
                try:
                    a, b, result = map(int, match.groups())
                    
                    # Check the operation based on pattern
                    if 'plus' in pattern or '+' in pattern:
                        correct = a + b
                    elif 'minus' in pattern or '-' in pattern:
                        correct = a - b
                    elif 'times' in pattern or '*' in pattern or '√ó' in pattern:
                        correct = a * b
                    elif 'divided' in pattern or '/' in pattern or '√∑' in pattern:
                        if b != 0:
                            correct = a // b  # Integer division for simplicity
                        else:
                            continue
                    else:
                        continue
                    
                    # If the stated result doesn't match the correct answer
                    if result != correct:
                        logger.info(f"üîç Math error detected: {a} {pattern.split('|')[0].strip('()')} {b} = {correct}, not {result}")
                        return True
                        
                except (ValueError, ZeroDivisionError):
                    continue
        
        return False
    
    def _detect_content_language(self, text: str) -> str:
        """Detect if content contains Dutch or English words"""
        dutch_indicators = [
            'en', 'is', 'het', 'de', 'een', 'van', 'dat', 'die', 'in', 'te', 'op', 'met', 'voor', 'als', 'zijn', 'er', 'maar', 'om', 'door', 'over', 'ze', 'bij', 'uit', 'ook', 'tot', 'je', 'mijn', 'aan', 'wel', 'of', 'dan', 'hem', 'had', 'zijn', 'meer', 'al', 'wat', 'andere', 'veel', 'geen', 'kan', 'man', 'nu', 'jaar', 'komen', 'mij', 'naar', 'tijd', 'hem', 'zei', 'elke', 'onder', 'tussen'
        ]
        
        english_indicators = [
            'the', 'and', 'is', 'it', 'you', 'that', 'he', 'was', 'for', 'on', 'are', 'as', 'with', 'his', 'they', 'i', 'at', 'be', 'this', 'have', 'from', 'or', 'one', 'had', 'by', 'word', 'but', 'not', 'what', 'all', 'were', 'we', 'when', 'your', 'can', 'said', 'there', 'each', 'which', 'she', 'do', 'how', 'their', 'if', 'will', 'up', 'other', 'about', 'out', 'many', 'then', 'them', 'these', 'so', 'some', 'her', 'would', 'make', 'like', 'into', 'him', 'has', 'two', 'more', 'very', 'after', 'words', 'first', 'where', 'much', 'through'
        ]
        
        words = text.lower().split()
        dutch_count = sum(1 for word in words if word in dutch_indicators)
        english_count = sum(1 for word in words if word in english_indicators)
        
        if dutch_count > english_count:
            return "dutch"
        elif english_count > dutch_count:
            return "english"
        else:
            return "mixed"
    
    def _clean_repetitive_text(self, text: str) -> str:
        """Clean repetitive patterns from transcription"""
        if not text or len(text) < 10:
            return text
        
        import re
        
        # Split into words
        words = text.split()
        if len(words) < 3:
            return text
        
        # Check for repetitive patterns
        # Pattern 1: Same word repeated many times
        word_counts = {}
        for word in words:
            clean_word = re.sub(r'[^\w]', '', word.lower())
            word_counts[clean_word] = word_counts.get(clean_word, 0) + 1
        
        # If any word appears more than 30% of the time, it's likely repetitive
        max_count = max(word_counts.values()) if word_counts else 0
        if max_count > len(words) * 0.3 and len(words) > 10:
            # Find the most common word
            most_common = max(word_counts.items(), key=lambda x: x[1])
            logger.info(f"üîç Detected repetitive pattern: '{most_common[0]}' appears {most_common[1]} times")
            
            # Try to extract meaningful content by looking for variations
            cleaned_words = []
            prev_word = ""
            consecutive_count = 0
            
            for word in words:
                clean_word = re.sub(r'[^\w]', '', word.lower())
                if clean_word == prev_word:
                    consecutive_count += 1
                    if consecutive_count <= 2:  # Keep first 2 occurrences
                        cleaned_words.append(word)
                else:
                    consecutive_count = 1
                    cleaned_words.append(word)
                    prev_word = clean_word
            
            # If we removed too much, return a summary
            if len(cleaned_words) < len(words) * 0.3:
                return f"[Repetitive audio pattern detected - likely counting or rhythm]"
            
            return " ".join(cleaned_words)
        
        # Pattern 2: Short phrase repeated
        if len(words) > 6:
            # Check for 2-word patterns
            for i in range(len(words) - 3):
                pattern = f"{words[i]} {words[i+1]}"
                pattern_count = 0
                for j in range(0, len(words) - 1):
                    if j + 1 < len(words) and f"{words[j]} {words[j+1]}" == pattern:
                        pattern_count += 1
                
                if pattern_count > len(words) // 4:  # Pattern appears frequently
                    logger.info(f"üîç Detected repetitive phrase: '{pattern}' appears {pattern_count} times")
                    return f"[Repetitive pattern: '{pattern}']"
        
        return text
    
    def _select_best_transcription(self, results: list) -> tuple:
        """Select the best transcription from multiple attempts"""
        if len(results) == 1:
            return results[0]
        
        scored_results = []
        
        for approach, result in results:
            text = result["text"].strip()
            score = 0
            
            # Score based on text length (prefer reasonable length)
            if 5 <= len(text) <= 200:
                score += 2
            elif len(text) > 0:
                score += 1
            
            # Score based on confidence if available
            if "segments" in result and result["segments"]:
                avg_confidence = sum(seg.get("avg_logprob", -2) for seg in result["segments"]) / len(result["segments"])
                # Convert logprob to positive score (higher is better)
                confidence_score = max(0, (avg_confidence + 2) * 2)  # Scale -2 to 0 ‚Üí 0 to 4
                score += confidence_score
            
            # Penalize repetitive patterns
            words = text.split()
            if len(words) > 3:
                unique_words = len(set(w.lower() for w in words))
                repetition_ratio = unique_words / len(words)
                if repetition_ratio < 0.3:  # Very repetitive
                    score -= 3
                elif repetition_ratio < 0.5:  # Somewhat repetitive
                    score -= 1
            
            # Bonus for reasonable speech patterns
            if any(word in text.lower() for word in ['the', 'and', 'is', 'are', 'can', 'will', 'have', 'this', 'that']):
                score += 1
            
            # Penalize obvious errors
            if text.lower() in ['you can fly', 'the fox can fly', 'elephant', 'owl']:
                score -= 2
            
            scored_results.append((score, approach, result))
            logger.info(f"   üìä '{approach}' score: {score:.2f} for '{text}'")
        
        # Return the highest scoring result
        best = max(scored_results, key=lambda x: x[0])
        logger.info(f"   üèÜ Best: '{best[1]}' with score {best[0]:.2f}")
        return (best[1], best[2])
    
    
    async def process_audio(self, audio_data: bytes, filename: str) -> AIProcessingResult:
        """Complete audio processing pipeline"""
        import time
        start_time = time.time()
        
        try:
            if not self.is_initialized:
                await self.initialize()
            
            logger.info(f"ü§ñ Starting AI processing for: {filename}")
            
            # Step 1: Transcribe audio
            transcription = await self.transcribe_audio(audio_data, filename)
            
            # Detect content language for better analysis
            content_language = self._detect_content_language(transcription)
            logger.info(f"‚úÖ Transcription: '{transcription}'")
            logger.info(f"üó£Ô∏è Content language detected: {content_language}")
            
            if transcription.startswith("Transcription failed"):
                return AIProcessingResult(
                    success=False,
                    error=transcription,
                    processing_time=time.time() - start_time
                )
            
            # Step 2: Try LLAMA with TinyLlama for fact-checking
            logger.info("üîÑ Starting fact-checking with TinyLlama...")
            
            # Start with fast analysis as base
            analysis_result = self._create_fast_analysis(transcription)
            
            # Try to enhance with LLAMA if available (non-blocking)
            try:
                llama_result = await self.analyze_with_llama(transcription, filename, model="tinyllama:latest", timeout=15)
                if llama_result:
                    # Merge LLAMA results with fast analysis
                    analysis_result.update({
                        "fact_check": llama_result.get("fact_check", analysis_result["fact_check"]),
                        "brutal_honesty": llama_result.get("brutal_honesty", analysis_result["brutal_honesty"]),
                        "credibility_score": llama_result.get("credibility_score", analysis_result["credibility_score"])
                    })
                    logger.info("‚úÖ Enhanced with TinyLlama fact-checking")
                else:
                    logger.info("‚ö° Using fast analysis (TinyLlama unavailable)")
            except Exception as e:
                logger.warning(f"‚ö° TinyLlama enhancement skipped: {e}")
            
            processing_time = time.time() - start_time
            logger.info(f"‚è±Ô∏è Total processing time: {processing_time:.2f} seconds")
            
            # Calculate confidence based on transcription length and quality
            confidence = min(0.95, len(transcription) / 100.0) if transcription else 0.1
            logger.info(f"üìä Calculated confidence score: {confidence:.3f}")
            
            # Create final result
            logger.info("üì¶ Building final AI processing result...")
            result = AIProcessingResult(
                success=True,
                transcription=transcription,
                analysis=analysis_result.get("analysis", "No analysis available"),
                summary=analysis_result.get("summary", "No summary available"),
                sentiment=analysis_result.get("sentiment", "neutral"),
                keywords=analysis_result.get("keywords", []),
                fact_check=analysis_result.get("fact_check", "No fact-checking performed"),
                brutal_honesty=analysis_result.get("brutal_honesty", "No brutal honesty assessment available"),
                credibility_score=analysis_result.get("credibility_score", 0.5),
                questionable_claims=analysis_result.get("questionable_claims", []),
                corrections=analysis_result.get("corrections", []),
                confidence=confidence,
                processing_time=processing_time
            )
            
            logger.info("‚úÖ AI processing completed successfully!")
            logger.info(f"üìã Final result summary:")
            logger.info(f"   ‚Ä¢ Transcription: {len(transcription)} chars")
            logger.info(f"   ‚Ä¢ Sentiment: {result.sentiment}")
            logger.info(f"   ‚Ä¢ Keywords: {len(result.keywords)} found")
            logger.info(f"   ‚Ä¢ Credibility: {result.credibility_score}")
            logger.info(f"   ‚Ä¢ Processing time: {processing_time:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"AI processing failed: {e}")
            return AIProcessingResult(
                success=False,
                error=str(e),
                processing_time=time.time() - start_time
            )

# Global processor instance
_processor = None

async def get_processor() -> LLAMAProcessor:
    """Get or create the global LLAMA processor"""
    global _processor
    if _processor is None:
        _processor = LLAMAProcessor()
        await _processor.initialize()
    return _processor

# Example usage
async def main():
    """Example usage of LLAMA processor"""
    processor = await get_processor()
    
    # Test with dummy audio data
    dummy_wav = b"RIFF" + b"\x00" * 100  # Dummy WAV data
    result = await processor.process_audio(dummy_wav, "test.wav")
    
    print(f"Success: {result.success}")
    if result.success:
        print(f"Transcription: {result.transcription}")
        print(f"Analysis: {result.analysis}")
        print(f"Sentiment: {result.sentiment}")
        print(f"Processing time: {result.processing_time:.2f}s")
    else:
        print(f"Error: {result.error}")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(main())
